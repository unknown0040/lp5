import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Importing the Boston Housing dataset
data = pd.read_csv("Boston.csv")
data.head()

#Shape of the data
print(data.shape)

#Checking the null values in the dataset
data.isnull().sum()

#Checking the statistics of the data
data.describe()

data.info()

#checking the distribution of the target variable
sns.distplot(data.medv)

sns.boxplot(data.medv)


# Checking the correlation of the independent feature with the dependent feature
correlation = data.corr()
correlation.loc['medv']

import matplotlib.pyplot as plt
fig,axes = plt.subplots(figsize=(10,10))
sns.heatmap(correlation,annot = True)

plt.figure(figsize=(20,5))
features = ['rm', 'lstat', 'ptratio']
for i, col in enumerate(features):
    plt.subplot(1, len(features), i+1)
    x=data[col]
    y=data.medv
    plt.scatter(x,y,marker='o')
    plt.title("Variation in house prices")
    plt.xlabel(col)
    plt.ylabel("House prices in 1000$")

from sklearn.model_selection import train_test_split
X = data.loc[:, data.columns != 'medv']
y = data.loc[:, data.columns == 'medv']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
mms.fit(X_train)
X_train = mms.transform(X_train)
X_test = mms.transform(X_test)



#Linear Regression
from sklearn.linear_model import LinearRegression

reg = LinearRegression()
#Fitting the model
reg.fit(X_train,y_train)


# Model Evaluation
#Prediction on the test dataset
y_pred = reg.predict(X_test)


# Predicting RMSE the Test set results
from sklearn.metrics import mean_squared_error
rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))
print(rmse)


# Neural Networks
#Scaling the dataset
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)


#Creating the neural network model
import keras
from keras.layers import Dense, Activation,Dropout
from keras.models import Sequential
model = Sequential()
model.add(Dense(128,activation = 'relu',input_dim =13))
model.add(Dense(64,activation = 'relu'))
model.add(Dense(32,activation = 'relu'))
model.add(Dense(16,activation = 'relu'))
model.add(Dense(1))

model.compile(optimizer = 'adam',loss ='mean_squared_error',metrics=['mae'])
model.summary()


history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)


from plotly.subplots import make_subplots
import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scattergl(y=history.history['loss'],

name='Train'))

fig.add_trace(go.Scattergl(y=history.history['val_loss'],

name='Valid'))

fig.update_layout(height=500, width=700,
xaxis_title='Epoch',
yaxis_title='Loss')

fig.show()


from plotly.subplots import make_subplots
import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scattergl(y=history.history['mae'],

name='Train'))

fig.add_trace(go.Scattergl(y=history.history['val_mae'],

name='Valid'))

fig.update_layout(height=500, width=700,
xaxis_title='Epoch',
yaxis_title='Loss')

fig.show()


#Evaluation of the model
y_pred = model.predict(X_test)
mse_nn, mae_nn = model.evaluate(X_test, y_test)
print('Mean squared error on test data: ', mse_nn)
print('Mean absolute error on test data: ', mae_nn)


from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_pred)
print(r2)


import sklearn
new_data = sklearn.preprocessing.StandardScaler().fit_transform(([[0.1, 10.0, 5.0, 0, 0.4, 6.0, 50, 6.0, 1, 400, 20, 300, 10]]))
prediction = model.predict(new_data)
print("Predicted house price:", prediction)